# -*- coding: utf-8 -*-
"""Projek Dicoding Machine Learning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14dxwE4TXGKFV54GzSAOyejLfGIgWZ5AJ

Nama : Kunti Najma Jaia
Email : najmajalia02@gmail.com
"""

# import tensorflow
import tensorflow as tf
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.preprocessing.image import ImageDataGenerator

# print tensorflow version
print(tf.__version__)

# download dataset
!wget --no-check-certificate https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip -O rockpaperscissors.zip

import zipfile,os
local_zip = 'rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('rps')
zip_ref.close()

!pip install split_folders

import splitfolders

splitfolders.ratio('rps/rockpaperscissors/rps-cv-images', 'rps/rockpaperscissors/data', seed=1, ratio=(.6, .4))

base_dir = 'rps/rockpaperscissors/data'
train_dir = os.path.join(base_dir, 'train')
validation_dir = os.path.join(base_dir, 'val')
os.listdir('rps/rockpaperscissors/data/train')
os.listdir('rps/rockpaperscissors/data/val')

train_batu_dir = os.path.join(train_dir, 'train')
train_gunting_dir = os.path.join(train_dir, 'guntung')
train_kertas_dir = os.path.join(train_dir, 'kertas')
 
validation_batu_dir = os.path.join(validation_dir, 'batu')
validation_guntung_dir = os.path.join(validation_dir, 'gunting')
validation_kertas_dir = os.path.join(validation_dir, 'kertas')

from keras.preprocessing.image import ImageDataGenerator
train_datagen = ImageDataGenerator(
  rescale=1./255, # skala ulang semua nilai piksel dari 0-255, jadi setelah langkah ini semua nilai piksel kita berada dalam rentang (0,1)
  shear_range=0.15, # untuk menerapkan beberapa transformasi acak 
  zoom_range=0.15, # untuk menerapkan zoom 
  horizontal_flip=True) # gambar akan menjadi sirip horiztest_datagen = ImageDataGenerator(rescale=1./255)

test_datagen = ImageDataGenerator(
  rescale=1./255, # skala ulang semua nilai piksel dari 0-255, jadi setelah langkah ini semua nilai piksel kita berada dalam rentang (0,1)
  shear_range=0.15, # untuk menerapkan beberapa transformasi acak 
  zoom_range=0.15, # untuk menerapkan zoom 
  horizontal_flip=True)

train_generator = train_datagen.flow_from_directory(
  train_dir, # atur ke jalur tempat kelas folder 'n' Anda ada. 
  target_size=(150, 150), # ukuran gambar input Anda, setiap gambar akan diubah ukurannya menjadi ukuran ini. 
  batch_size=32, # Jumlah gambar yang akan dihasilkan dari generator per batch. 
  color_mode='rgb', # jika gambar hitam putih atau skala abu-abu setel "skala abu-abu" atau jika gambar memiliki tiga saluran warna, setel "rgb". 
  class_mode='categorical', # Setel "biner" jika Anda hanya memiliki dua kelas untuk diprediksi, jika tidak disetel ke "kategorikal", jika Anda mengembangkan sistem Autoencoder, input dan output mungkin akan menjadi gambar yang sama, untuk kasus ini disetel ke "input" 
  shuffle = True, # Setel Benar jika Anda ingin mengacak urutan gambar yang dihasilkan, jika tidak, atur Salah 
  seed=42) # Benih acak untuk menerapkan pembesaran gambar acak dan mengacak urutan gambar.
validation_generator = test_datagen.flow_from_directory(
  validation_dir,
  target_size=(150, 150),
  batch_size=32,
  color_mode='rgb',
  class_mode='categorical',
  shuffle = True,
  seed=42)

sample_train_images, _ = next(train_generator)
sample_val_images, _ = next(validation_generator)

# Fungsi ini akan memplot gambar dalam bentuk grid dengan 1 baris dan 5 kolom dimana gambar ditempatkan di setiap kolom. 
def plotImages(images_arr):
    fig, axes = plt.subplots(1, 5, figsize=(20,20))
    axes = axes.flatten()
    for img, ax in zip( images_arr, axes):
        ax.imshow(img)
        ax.axis('off')
    plt.tight_layout()
    plt.show()

import matplotlib.pyplot as plt

plotImages(sample_train_images[:5])
plotImages(sample_val_images[:5])

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(256, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer=tf.optimizers.Nadam(),
              metrics=['accuracy'])

historrry = model.fit(train_generator, 
          steps_per_epoch=16, 
          epochs=20, 
          validation_data=validation_generator,
          validation_steps=5,
          verbose=1)

import matplotlib.pyplot as plt

acc = historrry.history['accuracy']
val_acc = historrry.history['val_accuracy']

loss = historrry.history['loss']
val_loss = historrry.history['val_loss']

plt.plot(acc, color='blue')
plt.plot(val_acc, color='red')
plt.title('model accuracy')
plt.ylabel('accuracy')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

plt.plot(loss, color='blue')
plt.plot(val_loss, color='red')
plt.title('model loss')
plt.ylabel('loss')
plt.xlabel('epoch')
plt.legend(['train', 'val'], loc='upper left')
plt.show()

import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline
 
uploaded = files.upload()
 
for fn in uploaded.keys():
 
  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))
  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
 
  images = np.vstack([x])
  classes = model.predict(images, batch_size=32)

  if classes[0,0]!=0:
    print('KERTAS')
  elif classes[0,1]!=0:
    print('BATU')
  else:
    print('GUNTING')